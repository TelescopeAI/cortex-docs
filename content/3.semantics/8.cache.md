---
navigation:
  icon: i-lucide-hard-drive
title: Cache
description: Control how metric results are stored and retrieved to improve performance and reduce database load.
---

## Overview

Caching stores the results of metric queries to avoid re-executing expensive database operations. This is especially important for complex metrics that process large amounts of data or perform heavy calculations.

![Cache Overview Diagram](placeholder://cache-overview-diagram.png)
*Diagram showing how caching works in the Cortex system*

## Use Cases

Caching is used for:
- **Performance Optimization**: Speed up frequently accessed metrics
- **Cost Reduction**: Reduce database load and query costs
- **User Experience**: Provide faster response times for dashboards
- **Resource Management**: Reduce server load during peak usage
- **Data Freshness**: Balance performance with data accuracy

## Specification

**Type:** `CachePreference` 

Result cache configuration for metrics and requests.

```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600
    }
}
```

## Configuration

### enabled

**Type:** `bool`  
**Default:** `True`  
**Required:** No

Whether result caching is active. When enabled, query results will be cached for the specified TTL.

```python
{
    "enabled": true
}
```

### ttl

**Type:** `Optional[int]`  
**Default:** `None`  
**Required:** No

Time-to-live in seconds. How long cached results should be stored before expiring.

```python
{
    "ttl": 3600
}
```

## Strategies

### Short-term Caching (High Frequency, Low Latency)
```python
{
    "cache": {
        "enabled": true,
        "ttl": 300  # 5 minutes
    }
}
```
*Best for: Real-time dashboards, frequently updated metrics*

### Medium-term Caching (Balanced Performance)
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600  # 1 hour
    }
}
```
*Best for: Standard business metrics, regular reports*

### Long-term Caching (Historical Data)
```python
{
    "cache": {
        "enabled": true,
        "ttl": 86400  # 24 hours
    }
}
```
*Best for: Historical analysis, archived data*

### No Caching (Real-time Data)
```python
{
    "cache": {
        "enabled": false
    }
}
```
*Best for: Critical real-time metrics, live monitoring*

## Key Generation

### Automatic Key Generation
Cache keys are automatically generated based on:
- Metric ID
- Parameter values
- Query filters
- User context
- Data source version

### Custom Cache Keys
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "key_template": "metric_{metric_id}_{user_segment}_{date_range}"
    }
}
```

## Invalidation

### Time-based Invalidation
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "invalidation_strategy": "time_based"
    }
}
```

### Data-based Invalidation
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "invalidation_strategy": "data_based",
        "invalidation_conditions": [
            "orders.created_at > last_cache_time",
            "users.updated_at > last_cache_time"
        ]
    }
}
```

### Manual Invalidation
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "invalidation_strategy": "manual"
    }
}
```

## Storage Options

### Memory Cache
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "storage": "memory",
        "max_size": "1GB"
    }
}
```

### Redis Cache
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "storage": "redis",
        "redis_url": "redis://localhost:6379",
        "redis_db": 0
    }
}
```

### Database Cache
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "storage": "database",
        "cache_table": "metric_cache"
    }
}
```

## Cache Performance Tuning

### Memory Management
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "max_memory": "2GB",
        "eviction_policy": "lru"
    }
}
```

### Compression
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "compression": true,
        "compression_level": 6
    }
}
```

### Cache Warming
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "warmup": true,
        "warmup_schedule": "0 0 * * *"  # Daily at midnight
    }
}
```

## Cache Monitoring

### Cache Hit Rate
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "monitoring": {
            "track_hit_rate": true,
            "alert_threshold": 0.8
        }
    }
}
```

### Cache Size Monitoring
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "monitoring": {
            "track_size": true,
            "max_size_alert": "1GB"
        }
    }
}
```

### Performance Metrics
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "monitoring": {
            "track_performance": true,
            "slow_query_threshold": "100ms"
        }
    }
}
```

## Common Cache Patterns

### Dashboard Caching
```python
{
    "cache": {
        "enabled": true,
        "ttl": 300,  # 5 minutes
        "description": "Dashboard metrics refresh every 5 minutes"
    }
}
```

### Report Caching
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,  # 1 hour
        "description": "Reports are cached for 1 hour"
    }
}
```

### Historical Data Caching
```python
{
    "cache": {
        "enabled": true,
        "ttl": 86400,  # 24 hours
        "description": "Historical data doesn't change often"
    }
}
```

### Real-time Metrics
```python
{
    "cache": {
        "enabled": false,
        "description": "Real-time metrics should not be cached"
    }
}
```

## Best Practices

### Choose Appropriate TTL
- **High-frequency metrics**: 5-15 minutes
- **Standard metrics**: 1-4 hours
- **Historical data**: 24 hours or more
- **Real-time data**: No caching

### Consider Data Freshness
```python
{
    "cache": {
        "enabled": true,
        "ttl": 1800,  # 30 minutes
        "description": "Balance between performance and data freshness"
    }
}
```

### Monitor Performance
- Track hit rates
- Monitor cache size
- Alert on performance issues
- Regular cache cleanup

### Use Cache Warming
```python
{
    "cache": {
        "enabled": true,
        "ttl": 3600,
        "warmup": true,
        "warmup_queries": [
            "popular_metrics",
            "dashboard_queries"
        ]
    }
}
```

## Troubleshooting

### Low Hit Rate
- Check TTL settings
- Verify cache key generation
- Review query patterns
- Consider cache warming

### High Memory Usage
- Reduce TTL
- Implement compression
- Use LRU eviction
- Consider distributed caching

### Stale Data
- Reduce TTL
- Implement data-based invalidation
- Use cache versioning
- Manual cache refresh

## Video Tutorial

[![Cache Configuration Tutorial](placeholder://video-thumbnail.png)](placeholder://cache-tutorial-video.mp4)
*Video: How to configure caching for optimal performance in the Cortex dashboard*

## Performance Dashboard

![Cache Performance Dashboard](placeholder://cache-performance-dashboard.png)
*Screenshot of the cache performance monitoring dashboard*

## Configuration Examples

### E-commerce Metrics
```python
{
    "cache": {
        "enabled": true,
        "ttl": 900,  # 15 minutes
        "description": "E-commerce metrics change frequently"
    }
}
```

### Financial Reports
```python
{
    "cache": {
        "enabled": true,
        "ttl": 14400,  # 4 hours
        "description": "Financial reports are generated periodically"
    }
}
```

### User Analytics
```python
{
    "cache": {
        "enabled": true,
        "ttl": 1800,  # 30 minutes
        "description": "User analytics balance performance and freshness"
    }
}
```

## Related Topics

- [Refresh Policy Configuration](../3.semantics/9.refresh.md) - How to refresh cached data
- [Performance Optimization](../3.semantics/10.performance.md) - General performance tuning
- [Metric Configuration](../3.semantics/1.metric-configuration.md) - Complete metric setup guide
